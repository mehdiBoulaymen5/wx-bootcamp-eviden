{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "## Prompt Lab Challenge Exercises Notebook\n\n### If you have troubles with your local installation you can use this notebook instead. \n\nPlease note that compared to the local version the set-up and the way the model is accessed and credentiasl are read are slightly different. "}, {"metadata": {}, "cell_type": "markdown", "source": "Welcome to the second prompt lab in the bootcamp series, you should have completed lab 1 and the exercises follow on from those. If you completed all the exercises in Lab 1 you should find most of the exercises here straightforward\n\nThis notebook is a template with all the exercises and indications of what the output should look like if you do a good job with the prompts.\n\nBefore you start you should have a Python environment with the necessary libraries installed as indicated in the intro lab, you will also need:\n- your IBM Cloud API key\n- the IBM Cloud regional URL (eg, https://us-south.ml.cloud.ibm.com)\n- the project ID associated with your WatsonX project (required by the WML Python SDK)\n\nIt should take you about 30-45 min to walk through the exercises self paced\n\nGood luck and make sure you compare your answers with the model solutions"}, {"metadata": {}, "cell_type": "code", "source": "import os\nfrom ibm_watson_machine_learning.foundation_models import Model\nfrom ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams", "execution_count": 1, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "import os, getpass, json\nimport requests\nfrom ibm_cloud_sdk_core import IAMTokenManager\nfrom ibm_cloud_sdk_core.authenticators import IAMAuthenticator, BearerTokenAuthenticator", "execution_count": 2, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Setup credentials"}, {"metadata": {}, "cell_type": "markdown", "source": "In the next steps, you need the credentials mentioned above, especially your IBM Cloud API key and IBM Cloud regional URL (eg, https://us-south.ml.cloud.ibm.com)"}, {"metadata": {}, "cell_type": "markdown", "source": "# Enter WML endpoint URL"}, {"metadata": {}, "cell_type": "code", "source": "endpoint_url = input(\"Please enter your WML endpoint url (hit enter): \")", "execution_count": 3, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Please enter your WML endpoint url (hit enter): https://us-south.ml.cloud.ibm.com\n"}]}, {"metadata": {}, "cell_type": "markdown", "source": "# Enter API Key"}, {"metadata": {}, "cell_type": "code", "source": "access_token = IAMTokenManager(\n    apikey = getpass.getpass(\"Please enter your IBM Cloud api key (hit enter): \"),\n    url = \"https://iam.cloud.ibm.com/identity/token\"\n).get_token()", "execution_count": 4, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Please enter your IBM Cloud api key (hit enter): \u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\n"}]}, {"metadata": {}, "cell_type": "markdown", "source": "# Enter Project ID\n\nSince we are working in a Cloud project, you should need to add anything here as it will be read from the notebook environment"}, {"metadata": {}, "cell_type": "code", "source": "try:\n    project_id = os.environ[\"PROJECT_ID\"]\nexcept KeyError:\n    project_id = input(\"Please enter your project_id (hit enter): \")", "execution_count": 5, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Helper function to set up model endpoint"}, {"metadata": {}, "cell_type": "code", "source": "# Helper Function\nclass Prompt:\n    def __init__(self, access_token, project_id):\n        self.access_token = access_token\n        self.project_id = project_id\n\n    def generate(self, input, model_id, parameters):\n        wml_url = f\"{endpoint_url}/ml/v1-beta/generation/text?version=2023-05-28\"\n        Headers = {\n            \"Authorization\": \"Bearer \" + self.access_token,\n            \"Content-Type\": \"application/json\",\n            \"Accept\": \"application/json\"\n        }\n        data = {\n            \"model_id\": model_id,\n            \"input\": input,\n            \"parameters\": parameters,\n            \"project_id\": self.project_id\n        }\n        response = requests.post(wml_url, json=data, headers=Headers)\n        if response.status_code == 200:\n            return response.json()[\"results\"][0]\n        else:\n            return response.text", "execution_count": 9, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Model and parameters\n\nChoose the model you want to use here and experiment with different parameters"}, {"metadata": {}, "cell_type": "code", "source": "# Model ID\nmodel_id=\"google/flan-ul2\"", "execution_count": 10, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Parameters\nparameters = {\n         \"decoding_method\": \"greedy\",\n         \"random_seed\": 33,\n         \"repetition_penalty\":1,\n         \"min_new_tokens\": 1,\n         \"max_new_tokens\": 5\n}", "execution_count": 11, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "#### Note that Q1 is challenging - consider doing it last in the lab\n#### Q1) Basic inference: A patients a1c level determines their diabetes status, the rules are as follows:\n\n - less than 5.7 no diabetes\n - between 5.7 and 6.5 pre-diabetes\n - greater than 6.5 diabetic.\n\nWrite a prompt to return just the diabetes status from the following 3 test cases:\n\n1)\tThe patients a1c is 5.5 which is good considering his other risk factors.\n2)\tFrom the last lab report I noted the A1c is 6.4 so we need to put her on Ozempic.\n3)\tShe mentioned her A1c is 8 according to her blood work about 3 years ago.\n\nBonus 1: How could you improve the inference given the other information in the sentences?\n\nBonus 2: how would you approach extracting the diabetes status based on patient notes without A1C values and what would you need to watch out for? (hint: maybe they are talking about family history of disease or other complications)\n"}, {"metadata": {}, "cell_type": "code", "source": "prompt = Prompt(access_token, project_id)", "execution_count": 12, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Q1 ENTER YOUR MODEL PARAMS HERE - MAKE SURE IT WORKS WITH ALL 3 EXAMPLES ABOVE\n# prompt = \" \"#complete your prompt here\nresponse = prompt.generate(\" \", model_id, parameters)", "execution_count": 13, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Product Review for Questions  2-6\n"}, {"metadata": {}, "cell_type": "code", "source": "# Product Review for Questions  2-6\nreview = \"\"\"Needed a nice lamp for my bedroom, and this one had \\\nadditional storage and not too high of a price point. \\\nGot it fast.  The string to our lamp broke during the \\\ntransit and the company happily sent over a new one. \\\nCame within a few days as well. It was easy to put \\\ntogether.  I had a missing part, so I contacted their \\\nsupport and they very quickly got me the missing piece! \\\nLumina seems to me to be a great company that cares \\\nabout their customers and products!!\"\"\"", "execution_count": 14, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "#### Q2) write a prompt to return the sentiment of the review\nTarget sentiment = positive"}, {"metadata": {}, "cell_type": "code", "source": "#Q2 Code - enter prompt and parameters in this cell\nprompt_text = \" \" # Complete your prompt here\nresponse = prompt.generate(prompt_text, model_id, parameters)", "execution_count": 17, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "response", "execution_count": 18, "outputs": [{"output_type": "execute_result", "execution_count": 18, "data": {"text/plain": "{'generated_text': '  ',\n 'generated_token_count': 5,\n 'input_token_count': 1,\n 'stop_reason': 'MAX_TOKENS'}"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "#### Q3) extract the emotions the reviewer expressed, return answer as a comma separated list\nTarget emotions = satisfied, happy, cared for, great company, product!"}, {"metadata": {}, "cell_type": "code", "source": "prompt_text = \" \" # Complete your prompt here\nresponse = prompt.generate(prompt_text, model_id, parameters)\nprint(response)", "execution_count": 22, "outputs": [{"output_type": "stream", "text": "{'generated_text': 'positive', 'generated_token_count': 2, 'input_token_count': 122, 'stop_reason': 'EOS_TOKEN'}\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "#### Q4) Is the reviewer expressing anger, answer \u201cyes\u201d or \u201cno\u201d \u2013 test with your own example including anger to ensure it works in both cases.\nTarget answer = no"}, {"metadata": {}, "cell_type": "code", "source": "prompt_text = \" \" # Complete your prompt here\nresponse = prompt.generate(prompt_text, model_id, parameters)\nprint(response)", "execution_count": 20, "outputs": [{"output_type": "stream", "text": "{'generated_text': '  ', 'generated_token_count': 5, 'input_token_count': 1, 'stop_reason': 'MAX_TOKENS'}\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "#### Q5) Extract the item purchased and the company name, return as JSON format\nTarget answer = Item[lamp], Brand[Lumina]"}, {"metadata": {}, "cell_type": "code", "source": "prompt_text = f\"\"\"\nIdentify the following items from the review text: \n- Item purchased by reviewer\n- Company that made the item\n\nThe review is delimited with triple backticks. \\\nFormat your response as a JSON object with \\\n\"Item\" and \"Brand\" as the keys. \nIf the information isn't present, use \"unknown\" \\\nas the value.\nMake your response as short as possible.\n  \nReview text: '''{review}'''\n\"\"\"\n\nprompt_text = \" \" # Complete your prompt here\nresponse = prompt.generate(prompt_text, model_id, parameters)\nprint(response)", "execution_count": 19, "outputs": [{"output_type": "stream", "text": "{'generated_text': '  ', 'generated_token_count': 5, 'input_token_count': 1, 'stop_reason': 'MAX_TOKENS'}\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "#### Q6) Can you combine 3-6 in a single prompt and return JSON with: Sentiment (negative or positive), Anger (yes/no), Product, Company\nTarget answer = Sentiment[positive], Anger[false], Item[lamp], Brand[Lumina]"}, {"metadata": {}, "cell_type": "code", "source": "prompt_text = \" \" # Complete your prompt here\nresponse = prompt.generate(prompt_text, model_id, parameters)\nprint(response)", "execution_count": null, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Sentiment[positive], Anger[false], Item[lamp], Brand[Lumina]\n"}]}, {"metadata": {}, "cell_type": "markdown", "source": "#### Q7) summarize the following product review\nExample summary = My daughter loves it!  It's soft and  super cute, and its face has a friendly look. It's  a bit small for what I paid though."}, {"metadata": {}, "cell_type": "code", "source": "review = \"\"\"Got this panda plush toy for my daughter's birthday, \\\nwho loves it and takes it everywhere. It's soft and \\ \nsuper cute, and its face has a friendly look. It's \\ \na bit small for what I paid though. I think there \\ \nmight be other options that are bigger for the \\ \nsame price. It arrived a day earlier than expected, \\ \nso I got to play with it myself before I gave it to her.\"\"\"", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "prompt_text = \" \" # Complete your prompt here\nresponse = prompt.generate(prompt_text, model_id, parameters)\nprint(response)", "execution_count": null, "outputs": [{"name": "stdout", "output_type": "stream", "text": "My daughter loves it!  It's soft and  super cute, and its face has a friendly look. It's  a bit small for what I paid though.\n"}]}, {"metadata": {}, "cell_type": "markdown", "source": "#### Q8) Summarize the same product review from the perspective of the shipping department\nExample summary = It arrived a day earlier than expected, so I got to play with it myself before I gave it  to her. "}, {"metadata": {}, "cell_type": "code", "source": "#concise wrt feedback shipping\nprompt_text = \" \" # Complete your prompt here\nresponse = prompt.generate(prompt_text, model_id, parameters)\nprint(response)", "execution_count": null, "outputs": [{"name": "stdout", "output_type": "stream", "text": "It arrived a day earlier than expected,  so I got to play with it myself before I gave it  to her. \n"}]}, {"metadata": {}, "cell_type": "markdown", "source": "#### Q9) Summarize the review from the perspective of pricing and value\nExample summary = It's a bit small for what I paid though. I think there might be other options that are bigger for the same price"}, {"metadata": {}, "cell_type": "code", "source": "#feedback pricing works - concise\nprompt_text = \" \" # Complete your prompt here\nresponse = prompt.generate(prompt_text, model_id, parameters)\nprint(response)", "execution_count": null, "outputs": [{"name": "stdout", "output_type": "stream", "text": "It's a bit small for what I paid though. I think there  might be other options that are bigger for the  same price\n"}]}, {"metadata": {}, "cell_type": "markdown", "source": "#### Q10)\tPII removal. Given the following email, write a prompt to remove the PII (eg names, emails etc) (Hint: you may need to use 1-2 shot technique)"}, {"metadata": {}, "cell_type": "code", "source": "email = \"\"\"\nHi John,\\\n\nI'm writing to you because I noticed you recently purchased a new car. I'm a salesperson\\\nat a local dealership (Cheap Dealz), and I wanted to let you know that we have a great deal on a new\\\ncar. If you're interested, please let me know.\\\n\nThanks,\\\n\nJimmy Smith\\\n\nPhone: 410-805-2345\\\nEmail: jimmysmith@cheapdealz.com\\\n\"\"\"", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Hint - use prompt template or manually construct the prompt with f strings (look up in documentation if unsure)"}, {"metadata": {}, "cell_type": "code", "source": "prompt_text = \" \" # Complete your prompt here\nresponse = prompt.generate(prompt_text, model_id, parameters)\nprint(response)", "execution_count": 23, "outputs": [{"output_type": "stream", "text": "{'generated_text': '  ', 'generated_token_count': 5, 'input_token_count': 1, 'stop_reason': 'MAX_TOKENS'}\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.10", "language": "python"}, "language_info": {"name": "python", "version": "3.10.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 4}