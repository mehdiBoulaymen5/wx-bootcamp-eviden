{"cells": [{"metadata": {}, "id": "b1788701", "cell_type": "markdown", "source": "# Lab 3: Intro to Building Prompt Templates with LangChain"}, {"metadata": {}, "id": "21c1bb64", "cell_type": "markdown", "source": "Welcome to the Lab 3. \n\nIn the previous lab, we explored the challenges of prompt engineering; learning how to tweak our wording, choose different models, plus optimize model parameters. Minor changes can significantly enhance the results generated by language models.\n\nIn this lab, we will apply our new knowledge to a real-world use case as we continue learning about best practices related to prompt coding. Using the [Watson Machine learning Python SDK](https://ibm.github.io/watson-machine-learning-sdk/) to programmatically interact with watsonx.ai, we will use prompt templating techniques provided by the [LangChain Python library](https://python.langchain.com/) to streamline our interactions with the language model and maximize its potential.\n\nThe concept of Prompt Templates provided by LangChain allows you to construct prompt templates that can be easily filled with specific information to generate a wide range of outputs that you can provide to watsonx.ai. You can even leverage prompt templates specific to few-shot prompting, as you will see below."}, {"metadata": {}, "id": "6110e08a", "cell_type": "markdown", "source": "## Recreating Prompt Builder Prompts Using LangChain Prompt Patterns"}, {"metadata": {}, "id": "d991e3a4", "cell_type": "markdown", "source": "### Scenario: Personalized Recommendation for XYZ Retail Company <a id=\"step3\"></a>"}, {"metadata": {}, "id": "4c7f1fb7", "cell_type": "markdown", "source": "XYZ Retail is a popular online retail store that sells a wide range of products, including electronics, clothing, home goods, and more. They have a large customer base and want to provide a personalized shopping experience to enhance customer satisfaction and boost sales.\n\nTo achieve that goal, XYZ wants to leverage generative AI to create fact sheets about each of their customers. These fact sheets will summarize relevant information such as customer demographics (name, age, location), and purchase history. These fact sheets will help XYZ Retail's sales team build stronger customer relationships, increase customer satisfaction and drive repeat purchases.\n"}, {"metadata": {}, "id": "d91d30ff", "cell_type": "markdown", "source": "You start by performing prompt engineering in Prompt Lab, and you might test base model output with an initial prompt like this:\n\n![title](./images/prompt_without_example.png)"}, {"metadata": {}, "id": "494a7da9", "cell_type": "markdown", "source": "The model's recommendation is not accurate or useful as the customer Michael Jones had bought toys and games not outdoor activewear. Fortunately you learned in the Prompt Engineering lab that Few Shot Learning can help you obtain better results. \n\nWhat happens when we provide a few examples using Prompt Builder to guide the LLM into generating more meaningful recommendations. \n\n![title](./images/prompt_with_example.png)\n"}, {"metadata": {}, "id": "20fad598", "cell_type": "markdown", "source": "Great, the product recommendation for Michael Jones is much better.  However how do you productionize your few shot prompting to generate recommendations for all of XYZ Retail customers? Copy and pasting each customer's info into Prompt Builder would take too long.  \n\nYou'll need a programmatic solution.  Maybe you could even generate a large set of examples then use that for Tuning a model in watsonx.ai.  But we're getting ahead of ourselves as you'll learn about building a Prompt Tuning dataset in a later lab."}, {"metadata": {"scrolled": true}, "id": "7aad0fba", "cell_type": "code", "source": "!pip install langchain==0.0.335\n#!pip install langchain-cli", "execution_count": 2, "outputs": [{"output_type": "stream", "text": "Collecting langchain==0.0.335\n  Downloading langchain-0.0.335-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from langchain==0.0.335) (6.0)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from langchain==0.0.335) (1.4.39)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from langchain==0.0.335) (3.8.5)\nCollecting anyio<4.0 (from langchain==0.0.335)\n  Downloading anyio-3.7.1-py3-none-any.whl.metadata (4.7 kB)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from langchain==0.0.335) (4.0.2)\nCollecting dataclasses-json<0.7,>=0.5.7 (from langchain==0.0.335)\n  Downloading dataclasses_json-0.6.2-py3-none-any.whl.metadata (25 kB)\nCollecting jsonpatch<2.0,>=1.33 (from langchain==0.0.335)\n  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\nCollecting langsmith<0.1.0,>=0.0.63 (from langchain==0.0.335)\n  Downloading langsmith-0.0.65-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: numpy<2,>=1 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from langchain==0.0.335) (1.23.5)\nCollecting pydantic<3,>=1 (from langchain==0.0.335)\n  Downloading pydantic-2.5.1-py3-none-any.whl.metadata (64 kB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m64.1/64.1 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: requests<3,>=2 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from langchain==0.0.335) (2.31.0)\nCollecting tenacity<9.0.0,>=8.1.0 (from langchain==0.0.335)\n  Downloading tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.335) (22.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.335) (2.0.4)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.335) (6.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.335) (1.8.1)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.335) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.335) (1.2.0)\nRequirement already satisfied: idna>=2.8 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from anyio<4.0->langchain==0.0.335) (3.4)\nCollecting sniffio>=1.1 (from anyio<4.0->langchain==0.0.335)\n  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\nCollecting exceptiongroup (from anyio<4.0->langchain==0.0.335)\n  Downloading exceptiongroup-1.1.3-py3-none-any.whl.metadata (6.1 kB)\nCollecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.335)\n  Downloading marshmallow-3.20.1-py3-none-any.whl.metadata (7.8 kB)\nCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.335)\n  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\nCollecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain==0.0.335)\n  Downloading jsonpointer-2.4-py2.py3-none-any.whl.metadata (2.5 kB)\nCollecting annotated-types>=0.4.0 (from pydantic<3,>=1->langchain==0.0.335)\n  Downloading annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\nCollecting pydantic-core==2.14.3 (from pydantic<3,>=1->langchain==0.0.335)\n  Downloading pydantic_core-2.14.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\nCollecting typing-extensions>=4.6.1 (from pydantic<3,>=1->langchain==0.0.335)\n  Downloading typing_extensions-4.8.0-py3-none-any.whl.metadata (3.0 kB)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.0.335) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.0.335) (2023.7.22)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.335) (2.0.1)\nRequirement already satisfied: packaging>=17.0 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.335) (23.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.335) (0.4.3)\nDownloading langchain-0.0.335-py3-none-any.whl (2.0 MB)\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading anyio-3.7.1-py3-none-any.whl (80 kB)\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m80.9/80.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading dataclasses_json-0.6.2-py3-none-any.whl (28 kB)\nDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\nDownloading langsmith-0.0.65-py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pydantic-2.5.1-py3-none-any.whl (381 kB)\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m381.6/381.6 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pydantic_core-2.14.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading tenacity-8.2.3-py3-none-any.whl (24 kB)\nDownloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\nDownloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\nDownloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\nDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\nDownloading exceptiongroup-1.1.3-py3-none-any.whl (14 kB)\nInstalling collected packages: typing-extensions, tenacity, sniffio, marshmallow, jsonpointer, exceptiongroup, annotated-types, typing-inspect, pydantic-core, jsonpatch, anyio, pydantic, dataclasses-json, langsmith, langchain\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing_extensions 4.4.0\n    Uninstalling typing_extensions-4.4.0:\n      Successfully uninstalled typing_extensions-4.4.0\n  Attempting uninstall: tenacity\n    Found existing installation: tenacity 8.0.1\n    Uninstalling tenacity-8.0.1:\n      Successfully uninstalled tenacity-8.0.1\nSuccessfully installed annotated-types-0.6.0 anyio-3.7.1 dataclasses-json-0.6.2 exceptiongroup-1.1.3 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.335 langsmith-0.0.65 marshmallow-3.20.1 pydantic-2.5.1 pydantic-core-2.14.3 sniffio-1.3.0 tenacity-8.2.3 typing-extensions-4.8.0 typing-inspect-0.9.0\n", "name": "stdout"}]}, {"metadata": {}, "id": "16a4d9fa", "cell_type": "markdown", "source": "## 1. Load the required libraries  <a id=\"step1\"></a>"}, {"metadata": {"tags": []}, "id": "212e985c", "cell_type": "code", "source": "import os\n\nimport pandas as pd\n#from langchain import PromptTemplate, FewShotPromptTemplate\nfrom ibm_watson_machine_learning.foundation_models import Model\nfrom ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams", "execution_count": 1, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from langchain.prompts.few_shot import FewShotPromptTemplate\nfrom langchain.prompts.prompt import PromptTemplate", "execution_count": 2, "outputs": [], "id": "661d9e25"}, {"metadata": {}, "id": "408eebee", "cell_type": "code", "source": "import langchain\nlangchain.__version__\n", "execution_count": 3, "outputs": [{"output_type": "execute_result", "execution_count": 3, "data": {"text/plain": "'0.0.335'"}, "metadata": {}}]}, {"metadata": {}, "id": "b9f48ad8", "cell_type": "markdown", "source": "## 2. Create a Factsheet for each customer using Prompt Patterns  <a id=\"step2\"></a>"}, {"metadata": {}, "id": "dd643142", "cell_type": "markdown", "source": "### **2.1 What is a Prompt Template?**\n\nThe [PromptTemplate class](https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/) in the [LangChain Python library](https://python.langchain.com/docs/get_started/introduction) provides a flexible approach to creating prompts from structured templates.  We will use the PrompTemplate class to simplify creation of our few shot prompts for XYZ Retail.\n\nXYZ Retail has provided you their customer's data in .csv format. To generate prompts for each customer, you will need to transform the prompt that you engineered in Prompt Builder into a more useful programmatic format. Using the PromptTemplate class, you can easily substitute customer data to generate one or multiple prompts.\n\nThe PromptTemplate class defines a schema where variables to replace are placed inside curly braces \"{}\". In Python parlance, it's simply using \"f-strings\" under the hood. These curly braces serve as a placeholder for the actual data that will be substituted into the template.\n\nLet's see how this works in practice."}, {"metadata": {}, "id": "21bcfa88", "cell_type": "markdown", "source": "### **2.2 Creating a simple prompt from a template**\n\nA prompt template can be created using the PromptTemplate class from a string or .txt file. There are [additional PromptTemplate examples](https://api.python.langchain.com/en/latest/prompts/langchain.prompts.prompt.PromptTemplate.html#langchain.prompts.prompt.PromptTemplate) provided in the LangChain documentation."}, {"metadata": {}, "id": "1cfc5148", "cell_type": "markdown", "source": "#### 2.2.1 Prompt Template From String"}, {"metadata": {}, "id": "cbd465f4-448c-46e8-b829-79693881df23", "cell_type": "code", "source": "# template is a string with variable names in curly brackets\npattern = \"input: {name} {family_name} is {age} and lives in {location}. They bought {purchase_history}\"\n\n# generate template\nprompt_template = PromptTemplate.from_template(pattern)\nprompt_template.template", "execution_count": 4, "outputs": [{"output_type": "execute_result", "execution_count": 4, "data": {"text/plain": "'input: {name} {family_name} is {age} and lives in {location}. They bought {purchase_history}'"}, "metadata": {}}]}, {"metadata": {}, "id": "90cdc428-2bc7-4062-957e-13f75dabafdd", "cell_type": "code", "source": "# now let's provide some values and generate our prompt\n# notice how the variables coincide with those we specified in curly brackets\nprompt = prompt_template.format(name=\"Jane\", \n                                family_name=\"Doe\",\n                                age=43,\n                                location=\"San Francisco, CA\",\n                                purchase_history = \"groceries, household goods and travel supplies\")\n\nprompt", "execution_count": 5, "outputs": [{"output_type": "execute_result", "execution_count": 5, "data": {"text/plain": "'input: Jane Doe is 43 and lives in San Francisco, CA. They bought groceries, household goods and travel supplies'"}, "metadata": {}}]}, {"metadata": {}, "id": "fe6a6cdb", "cell_type": "markdown", "source": "#### 2.2.2 Prompt Template From File\nPrompt patterns can also be stored as a txt file:"}, {"metadata": {}, "id": "35b5ba71", "cell_type": "code", "source": "!mkdir templates\n!curl https://raw.githubusercontent.com/mehdiBoulaymen5/wx-dubai-bootcamp/main/self-guided-labs/level-1/lab-03-langchain-prompt-template/templates/customer_factsheet_lang.txt -o ./templates/customer_factsheet_lang.txt", "execution_count": 53, "outputs": [{"output_type": "stream", "text": "mkdir: cannot create directory \u2018templates\u2019: File exists\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100   215  100   215    0     0   1535      0 --:--:-- --:--:-- --:--:--  1535\n", "name": "stdout"}]}, {"metadata": {}, "id": "e9f333bd", "cell_type": "code", "source": "!ls templates", "execution_count": 54, "outputs": [{"output_type": "stream", "text": "customer_factsheet_lang.txt\r\n", "name": "stdout"}]}, {"metadata": {"tags": [], "scrolled": true}, "id": "72f1cf1f", "cell_type": "code", "source": "# We create a template from a file:\n_path_to_file = \"./templates/customer_factsheet_lang.txt\"\n\n# this time we provide the variable names in a list\nexample_prompt = PromptTemplate.from_file(_path_to_file,\n                                input_variables=[\"name\", \"family_name\", \"age\",\"city\", \"state\", \n                                                 \"purchase_history\", \"recommendation_1\", \"recommendation_2\"])\n\nprint(example_prompt.template)", "execution_count": 55, "outputs": [{"output_type": "stream", "text": "input: \"{name} {family_name} is {age} years old and lives in {city}, {state}. Their purchase history includes {purchase_history}.\"\noutput: \"Recommendations:\\n Item 1: {recommendation_1}\\nItem 2: {recommendation_2}\"\n\n", "name": "stdout"}]}, {"metadata": {}, "id": "2d5647f4", "cell_type": "markdown", "source": "Just like in 2.1, we can populate this teamplate from a dictionary containing the values of the input variables. Looping over three examples:"}, {"metadata": {"tags": []}, "id": "9f8ae595", "cell_type": "code", "source": "# we can iterate through a list to populate the template\n\nexamples = [\n    {\n        \"name\":\"Jane\", \n        \"family_name\":\"Doe\", \n        \"age\":43, \n        \"city\":\"San Francisco\", \n        \"state\":\"CA\",\n        \"purchase_history\":\"groceries, household goods and travel supplies\", \n        \"recommendation_1\":\"Basket of organic fruits\",\n        \"recommendation_2\":\"Lightweight carry-on suitcase\"\n    },{\n        \"name\":\"Siamak\", \n        \"family_name\":\"Baharoo\", \n        \"age\":57, \n        \"city\":\"Chicago\", \n        \"state\":\"IL\",\n        \"purchase_history\":\"Books electronics home_goods\", \n        \"recommendation_1\":\"Kindle Paperwhite - This e-reader is perfect for book lovers who want a lightweight and portable device that can hold thousands of books. It has a glare-free display and a long battery life, so you can read for hours on end without having to worry about running out of power.\",\n        \"recommendation_2\": \"Google Home Mini - This smart speaker is perfect for controlling your home's smart devices with your voice. You can use it to play music, set alarms, get news, and more. It's also a great way to stay connected with friends and family.\"\n    },{\n        \"name\":\"Luis\", \n        \"family_name\":\"Cooli\", \n        \"age\":21, \n        \"city\":\"New York City\", \n        \"state\":\"NY\",\n        \"purchase_history\":\"Clothing shoes cosmetics\", \n        \"recommendation_1\":\"Aritzia Wilfred Free Sweater - This soft and cozy sweater is perfect for a casual day out. It's available in a variety of colors, so you can find the perfect one to match your style.\",\n        \"recommendation_2\":\"Steve Madden Pointed Toe Pumps - These stylish pumps are perfect for a night out on the town. They're comfortable and versatile, so you can wear them with a variety of outfits.\"\n    }\n]\n\nfor example in examples: \n    \n    print(example_prompt.format(**example))\n    ", "execution_count": 57, "outputs": [{"output_type": "stream", "text": "input: \"Jane Doe is 43 years old and lives in San Francisco, CA. Their purchase history includes groceries, household goods and travel supplies.\"\noutput: \"Recommendations:\\n Item 1: Basket of organic fruits\\nItem 2: Lightweight carry-on suitcase\"\n\ninput: \"Siamak Baharoo is 57 years old and lives in Chicago, IL. Their purchase history includes Books electronics home_goods.\"\noutput: \"Recommendations:\\n Item 1: Kindle Paperwhite - This e-reader is perfect for book lovers who want a lightweight and portable device that can hold thousands of books. It has a glare-free display and a long battery life, so you can read for hours on end without having to worry about running out of power.\\nItem 2: Google Home Mini - This smart speaker is perfect for controlling your home's smart devices with your voice. You can use it to play music, set alarms, get news, and more. It's also a great way to stay connected with friends and family.\"\n\ninput: \"Luis Cooli is 21 years old and lives in New York City, NY. Their purchase history includes Clothing shoes cosmetics.\"\noutput: \"Recommendations:\\n Item 1: Aritzia Wilfred Free Sweater - This soft and cozy sweater is perfect for a casual day out. It's available in a variety of colors, so you can find the perfect one to match your style.\\nItem 2: Steve Madden Pointed Toe Pumps - These stylish pumps are perfect for a night out on the town. They're comfortable and versatile, so you can wear them with a variety of outfits.\"\n\n", "name": "stdout"}]}, {"metadata": {}, "id": "eb85c4bd", "cell_type": "markdown", "source": "## 3. Create Prompt Examples based on Customers Factsheet <a id=\"step3\"></a>\nThe value of PromptTemplate arises when generating a large number of prompts either as examples for bulk evaluation of an engineered prompt or for creation of a Tuning dataset"}, {"metadata": {}, "id": "f704ef15", "cell_type": "markdown", "source": "### 3.1 Create a few shot prompt\nWe will start by creating a FewShotPromptTemplate object. This class allows to create a prompt made of few repetitions of a PromptTemplate. Details can be found in the [FewShotPromptTemplate class documentation](https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/few_shot_examples)"}, {"metadata": {"tags": []}, "id": "a4389d2d", "cell_type": "code", "source": "# Next step create a few shot prompt template\n\nfew_shot_examples = examples[:2]\nfew_shot_input = examples[2].copy()\ndel few_shot_input['recommendation_1']\ndel few_shot_input['recommendation_2']\n\ndef make_few_shot_prompt(few_shot_examples, few_shot_input):\n    \"\"\"\n    Generate a few-shot prompt using the FewShotPromptTemplate class.\n\n    Parameters:\n    - few_shot_examples: List of examples to be shown as few-shot examples.\n    - few_shot_input: Input for which the prompt will be generated.\n\n    Returns:\n    - A string representing the formatted few-shot prompt.\n    \"\"\"\n    prompt = FewShotPromptTemplate(\n        examples=few_shot_examples, \n        example_prompt=example_prompt, \n        suffix='input: \"{name} {family_name} is {age} years old and lives in {city}, {state}. Their purchase history includes {purchase_history}.\"\\noutput: ', \n        input_variables=[\"name\", \"family_name\", \"age\", \"city\",\"state\", \"purchase_history\"]\n    )\n    # Return the formatted prompt using the provided input data\n    #print(few_shot_input)\n    #return few_shot_input\n    return prompt.format(**few_shot_input)\n\n\nfew_shot_prompt = make_few_shot_prompt(few_shot_examples, few_shot_input)\nprint(few_shot_prompt)", "execution_count": 59, "outputs": [{"output_type": "stream", "text": "input: \"Jane Doe is 43 years old and lives in San Francisco, CA. Their purchase history includes groceries, household goods and travel supplies.\"\noutput: \"Recommendations:\\n Item 1: Basket of organic fruits\\nItem 2: Lightweight carry-on suitcase\"\n\n\ninput: \"Siamak Baharoo is 57 years old and lives in Chicago, IL. Their purchase history includes Books electronics home_goods.\"\noutput: \"Recommendations:\\n Item 1: Kindle Paperwhite - This e-reader is perfect for book lovers who want a lightweight and portable device that can hold thousands of books. It has a glare-free display and a long battery life, so you can read for hours on end without having to worry about running out of power.\\nItem 2: Google Home Mini - This smart speaker is perfect for controlling your home's smart devices with your voice. You can use it to play music, set alarms, get news, and more. It's also a great way to stay connected with friends and family.\"\n\n\ninput: \"Luis Cooli is 21 years old and lives in New York City, NY. Their purchase history includes Clothing shoes cosmetics.\"\noutput: \n", "name": "stdout"}]}, {"metadata": {}, "id": "682e71a4", "cell_type": "markdown", "source": "### 3.2 Bulk Creation of Prompts\nUsing the FewShotPromptTemplate class, we can now create a function that generates a list a few shot prompts populating them iteratively from values directy extracted from a notebook.\n\nWe can choose how many single prompts are include in one few shot prompt. The output of the function is a list of few shot prompts. "}, {"metadata": {}, "id": "a74a666d", "cell_type": "code", "source": "!mkdir data\n!curl https://raw.githubusercontent.com/mehdiBoulaymen5/wx-dubai-bootcamp/main/self-guided-labs/level-1/lab-03-langchain-prompt-template/data/customer_factsheet.csv  --output ./data/customer_factsheet.csv\n", "execution_count": 60, "outputs": [{"output_type": "stream", "text": "mkdir: cannot create directory \u2018data\u2019: File exists\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100  2561  100  2561    0     0  77606      0 --:--:-- --:--:-- --:--:-- 77606\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "!ls -la data", "execution_count": 61, "outputs": [{"output_type": "stream", "text": "total 44\r\ndrwxrwx--- 2 wsuser wscommon  4096 Nov 20 07:54 .\r\ndrwxrwx--- 4 wsuser wscommon  4096 Nov 20 07:47 ..\r\n-rw-rw---- 1 wsuser wscommon   580 Nov 20 07:44 customer_factsheet2.csv\r\n-rw-rw---- 1 wsuser wscommon 10670 Nov 20 07:48 customer_factsheet3.csv\r\n-rw-rw---- 1 wsuser wscommon 10861 Nov 20 07:52 customer_factsheet5.csv\r\n-rw-rw---- 1 wsuser wscommon  2561 Nov 20 07:54 customer_factsheet6.csv\r\n-rw-rw---- 1 wsuser wscommon  2561 Nov 20 07:55 customer_factsheet.csv\r\n", "name": "stdout"}], "id": "5fc23a37"}, {"metadata": {"tags": []}, "id": "c10d7db8", "cell_type": "code", "source": "# Specify the path to the CSV file containing the data\ncsv_file_path = \"./data/customer_factsheet.csv\"\n\ndef sub_all_from_csv(csv_file_path, n_prompt_examples=2):\n    \"\"\"\n    Generates a list of few-shot prompts using the FewShotPromptTemplate class. \n    The prompts are populated iteratively from values extracted from a CSV file.\n\n    Parameters:\n    - csv_file_path: The path to the CSV file.\n    - n_prompt_examples: The number of examples included in one few-shot prompt.\n\n    Returns:\n    - list_of_prompts: A list of few-shot prompts.\n    \"\"\"\n\n    df = pd.read_csv(csv_file_path)\n   \n    examples = [example for _, example in df.transpose().to_dict().items()]\n\n    i=0\n    list_of_prompts = []\n\n    while i < len(df):\n        few_shot_examples = examples[i:i+n_prompt_examples]\n        few_shot_input = examples[i+n_prompt_examples].copy()\n        del few_shot_input['recommendation_1']\n        del few_shot_input['recommendation_2']\n\n        list_of_prompts.append(make_few_shot_prompt(few_shot_examples, few_shot_input))\n        \n        i = i+n_prompt_examples +1\n\n    # Return the list of few-shot prompts\n    return list_of_prompts", "execution_count": 63, "outputs": []}, {"metadata": {"tags": []}, "id": "b6fab6fe", "cell_type": "code", "source": "list_of_prompts = sub_all_from_csv(csv_file_path)\nprint(list_of_prompts[0])", "execution_count": 64, "outputs": [{"output_type": "stream", "text": "input: \"John Smith is 30 years old and lives in San Francisco, CA. Their purchase history includes Books electronics home_goods.\"\noutput: \"Recommendations:\\n Item 1: Kindle Paperwhite - This e-reader is perfect for book lovers who want a lightweight and portable device that can hold thousands of books. It has a glare-free display and a long battery life, so you can read for hours on end without having to worry about running out of power.\\nItem 2: Google Home Mini - This smart speaker is perfect for controlling your home's smart devices with your voice. You can use it to play music, set alarms, get news, and more. It's also a great way to stay connected with friends and family.\"\n\n\ninput: \"Jane Doe is 25 years old and lives in New York, NY. Their purchase history includes Clothing shoes cosmetics.\"\noutput: \"Recommendations:\\n Item 1: Aritzia Wilfred Free Sweater - This soft and cozy sweater is perfect for a casual day out. It's available in a variety of colors, so you can find the perfect one to match your style.\\nItem 2: Steve Madden Pointed Toe Pumps - These stylish pumps are perfect for a night out on the town. They're comfortable and versatile, so you can wear them with a variety of outfits.\"\n\n\ninput: \"Michael Jones is 40 years old and lives in Seattle, WA. Their purchase history includes Toys games sporting_goods.\"\noutput: \n", "name": "stdout"}]}, {"metadata": {}, "id": "00860a91", "cell_type": "markdown", "source": "### 3.2 Additional Examples\nYou can explore [additional examples using the PromptTemplate](https://api.python.langchain.com/en/latest/prompts/langchain.prompts.prompt.PromptTemplate.html#langchain.prompts.prompt.PromptTemplate)"}, {"metadata": {}, "id": "ed11a20a", "cell_type": "markdown", "source": "## 4. Prompt evaluation and few shot learning from bulk created prompts <a id=\"step4\"></a>\nIn the prior examples, you created a \"2-shot learning\" prompt.  I.e. there were three inputs but only two complete outputs.  By using a larger dataset this way, you can perform bulk testing of your prompt.\n\nE.g. two of your data samples are used to train before generating the \"output\" of the 3rd. You can now execute these few shot prompts to see how well our engineered prompt works across numerous examples"}, {"metadata": {}, "id": "7e7b5ffb", "cell_type": "markdown", "source": "### 4.1 Import Watsonx.ai access credentials and load model\nMake sure you copied the .env file that you created earlier into the same directory as this notebook"}, {"metadata": {}, "cell_type": "code", "source": "api_key = 'S6P8WbAt9-KR-P5zQQ-6W8h0UqfZZuD3-u9oaiOsT6Uu'\nibm_cloud_url = \"https://eu-de.ml.cloud.ibm.com\"\nproject_id = \"00e43b61-b7a6-4ed9-aabf-3650f23d4b91\"", "execution_count": 65, "outputs": [], "id": "8c17caf9"}, {"metadata": {}, "id": "b0ea437e", "cell_type": "code", "source": "\nif api_key is None or ibm_cloud_url is None or project_id is None:\n    print(\"Ensure you copied the .env file that you created earlier into the same directory as this notebook\")\nelse:\n    creds = {\n        \"url\": ibm_cloud_url,\n        \"apikey\": api_key \n    }\n\n\nmodel_params = {\n    GenParams.DECODING_METHOD: \"greedy\",\n    GenParams.MIN_NEW_TOKENS: 50,\n    GenParams.MAX_NEW_TOKENS: 100\n}\n\n# Instantiate a model proxy object to send your requests\nmodel = Model(\n    model_id='google/flan-ul2',\n    params=model_params,\n    credentials=creds,\n    project_id=project_id)", "execution_count": 66, "outputs": []}, {"metadata": {}, "id": "8053738c", "cell_type": "markdown", "source": "### 4.2 Send prompts to Watsonx.ai"}, {"metadata": {}, "id": "8e3ee91c", "cell_type": "code", "source": "responses = [model.generate_text(prompt) for prompt in list_of_prompts]\nfor i, response in enumerate(responses):\n    lines = str(list_of_prompts[i]).strip().split(\"\\n\")\n    user_description = str(lines[4])\n    print(f\"\\n{user_description}\")\n    print(f\"\\n MODEL OUTPUT: {response}\")", "execution_count": 67, "outputs": [{"output_type": "stream", "text": "\ninput: \"Jane Doe is 25 years old and lives in New York, NY. Their purchase history includes Clothing shoes cosmetics.\"\n\n MODEL OUTPUT: \"Recommendations:n Item 1: X-Box One - The X-Box One is the latest in the X-Box line of gaming systems. It features a high definition 1080p screen, a high-powered GPU, and a high-performance CPU. It also has Kinect, which allows you to play games by simply moving your body.nItem 2: X-Box 360 - The X\n\ninput: \"David Williams is 60 years old and lives in Atlanta, GA. Their purchase history includes Groceries household_items travel_items.\"\n\n MODEL OUTPUT: \"Recommendations:n Item 1: Makeup - MAC Ruby Woo LipsticknItem 2: Skincare - Clinique Dramatically Different MoisturizernItem 3: Fashion - MAC x Patrick Starrr CollectionnItem 4: Location - Los Angeles, CAn\n\ninput: \"Daniel Miller is 45 years old and lives in Houston, TX. Their purchase history includes Books music movies.\"\n\n MODEL OUTPUT: \"Recommendations:n Item 1: RefrigeratornItem 2: FurniturenItem 3: AppliancesnItem 4: Home Improvement SuppliesnnItem 5: HomenItem 6: FurniturenItem 7: AppliancesnItem 8: HomenItem 9: Home Improvement SuppliesnItem 10: HomenItem 11: FurniturenItem 12: Home\n", "name": "stdout"}]}, {"metadata": {}, "id": "a1ab967e", "cell_type": "markdown", "source": "### Few shot prompt analysis\nThese results are not bad.  An X-Box for a customer with a history of buying toys and games.  Likewise cosmetics and furniture for the other two customers accurately reflects their purchase history.  "}, {"metadata": {}, "id": "d599c479", "cell_type": "markdown", "source": "## 5. Congratulations\nCongratulations on completing the lab and exploring the fascinating world of bulk creation of Few Shot Prompts using PromptTemplate! \n\nThrough the practical use case of generating personalized product recommendations, you have witnessed the power of tailoring prompts to individual customer profiles. By incorporating customer-specific details and programmatically generating bulk examples, you can fine-tune the model for your specific use case, resulting in more accurate and tailored outputs. \n\nContinuously iterating and refining your prompts based on these examples will unlock the full potential of language models and enhance their performance across various domains. Keep experimenting and leveraging prompt engineering techniques to optimize your interactions with language models and drive impactful results in your projects."}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.10", "language": "python"}, "language_info": {"name": "python", "version": "3.10.13", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 5}